
https://chatai.aritek.app


curl -X POST "https://chatai.aritek.app/stream" \
  -H "Accept: text/event-stream" \
  -H "Content-Type: application/json" \
  -H "User-Agent: Dalvik/2.1.0 (Linux; U; Android 7.1.2; SM-G935F Build/N2G48H)" \
  -H "Host: chatai.aritek.app" \
  -H "Connection: Keep-Alive" \
  -d "{
    "machineId": "0343578260151264.464241743263788731",
    "msg": [
      {"role": "user", "content": "你是什么模型？"}
    ],
    "token": "eyJzdWIiOiIyMzQyZmczNHJ0MzR0MzQiLCJuYW1lIjoiSm9objM0NTM0NT",
    "type": 0
  }"



https://chat9.yqcloud.top

curl -X POST "https://api.binjie.fun/api/generateStream" \
  -H "accept: application/json, text/plain, */*" \
  -H "accept-language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7" \
  -H "content-type: application/json" \
  -H "dnt: 1" \
  -H "origin: https://chat9.yqcloud.top" \
  -H "priority: u=1, i" \
  -H "referer: https://chat9.yqcloud.top/" \
  -H "sec-ch-ua: \"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand\";v=\"24\"" \
  -H "sec-ch-ua-mobile: ?0" \
  -H "sec-ch-ua-platform: \"macOS\"" \
  -H "sec-fetch-dest: empty" \
  -H "sec-fetch-mode: cors" \
  -H "sec-fetch-site: cross-site" \
  -H "user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36" \
  --data-raw '{
    "prompt": "你是什么模型",
    "userId": """#/chat/$(date +%s%3N)""",
    "network": true,
    "system": "你是我的个人小助手",
    "withoutContext": false,
    "stream": true
  }'

curl -N -X POST "https://api.binjie.fun/api/generateStream" \
-H "accept: application/json, text/plain, */*" \
-H "accept-language: en-US,en;q=0.9" \
-H "content-type: application/json" \
-H "origin: https://chat9.yqcloud.top" \
-H "referer: https://chat9.yqcloud.top/" \
-H "user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" \
--data-raw '{
  "prompt": "user: 我是sanbo\nassistant: Hi there!\nuser: 我是谁?",
  "userId": "#/chat/$(date +%s%3N)",
  "network": true,
  "system": "You are a helpful assistant.",
  "withoutContext": false,
  "stream": true
}'


https://koala.sh/chat

curl "https://koala.sh/api/gpt/" \
  -H "accept: text/event-stream" \
  -H "accept-language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7" \
  -H "content-type: application/json" \
  -H "flag-real-time-data: false" \
  -H "origin: https://koala.sh" \
  -H "priority: u=1, i" \
  -H "referer: https://koala.sh/chat" \
  -H "sec-ch-ua: "Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"" \
  -H "sec-ch-ua-mobile: ?0" \
  -H "sec-ch-ua-platform: "Windows"" \
  -H "sec-fetch-dest: empty" \
  -H "sec-fetch-mode: cors" \
  -H "sec-fetch-site: same-origin" \
  -H "user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36" \
  -H "visitor-id: M104xcG4CrFMUerYxF05" \
  --data-raw $"{"input":"hi","inputHistory":["hi"],"outputHistory":["Hello\u0021 How can I assist you today?"],"model":"gpt-4.1-mini"}"



curl -X POST "https://koala.sh/api/gpt/" \
  -H "User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:122.0) Gecko/20100101 Firefox/122.0" \
  -H "Accept: text/event-stream" \
  -H "Accept-Language: de,en-US;q=0.7,en;q=0.3" \
  -H "Referer: https://koala.sh/chat" \
  -H "Flag-Real-Time-Data: false" \
  -H "Visitor-ID: $(openssl rand -hex 10)" \
  -H "Origin: https://koala.sh" \
  -H "Alt-Used: koala.sh" \
  -H "Sec-Fetch-Dest: empty" \
  -H "Sec-Fetch-Mode: cors" \
  -H "Sec-Fetch-Site: same-origin" \
  -H "TE: trailers" \
  -H "Content-Type: application/json" \
  --data-raw '{
    "input": "你是谁",
    "inputHistory": [],
    "outputHistory": [],
    "model": "gpt-4o-mini"
  }'


curl 'https://koala.sh/api/gpt/' \
  -H 'accept: text/event-stream' \
  -H 'accept-language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7' \
  -H 'content-type: application/json' \
  -b '_ga=GA1.1.135562489.1750346767; crisp-client%2Fsession%2Fb21d4851-f776-4e10-bd26-bef59f54886b=session_089e7dd9-abf3-4030-9a18-471b53b0bd5c; __stripe_mid=38b1254a-4bf6-47b7-bea2-521320c2ec7eccf3f0; _ga_9LCF2TJ2CY=GS2.1.s1750346767$o1$g1$t1750347235$j56$l0$h0; cf_clearance=YYMxb4yyeVm1PbloBVjeBoLgVuWA_ZHKlhCocXqkelg-1750604658-1.2.1.1-6rSwpk64gwSlGGQ8B1Jz7uOhOaRmoJ7badfxHDZ45Oa5WSLMiVO9Og3NSHdR8vO7TxvPv7RnuBYlhQnga9uBBmPKHUr8yPvC9749fe87Ak626xn9BWDf8gWCoYC4bvPCibP.8UUoMjCr36VCeCD458XAnXwY2UdixKzLdEhZ7PjopyvGiEnHuE.eHB61T.FT0czkeNg5Gff1E5Ne7ciD_EpWY58FlflGxv1dvuz__e8VMh96zbqVMvyeOQ64rgW1QFVEbvZJmNCV.dyke76F.6MrdkfpLU.D518YEovmgwrrFZZHxcpGYBjtjiEvBy37_ZrEFxsKuvqN87zIUqK6PksWn3pz3ecCi1Fk8Fvp3RE; _iidt=ZNotD0v/7EryLDKgMfPJkHRUD0wkAF2z640m0j7Bg/Yhml3oFu1ZrI01GTDSk+zMKV0xEi93enabFTn9Oj23+KYdqPqHM3+1pmUDLac=; _vid_t=otB8AS0XrWc4IFyp/yLrAS7/4sA7Gx09/XvnpcS3YjoBf4ilhBCRXZqSmnVCP8wOREn1C3VgFK/x00Lqr0qXo+6C5L7lIX6xUQaJ8PM=; __stripe_sid=c2cc3f5c-38d0-474f-9ff2-2b7ad43aff1d0628cb; ph_phc_sUBgtFpFGfL4lIY24ZS4PcZTNaRvtHCCh3XdWQE29CO_posthog=%7B%22distinct_id%22%3A%2201979833-dae0-774d-afef-6677cf0db295%22%2C%22%24sesid%22%3A%5B1750605230767%2C%2201979833-f2af-709b-b7cb-502b837c22d8%22%2C1750605230767%5D%7D' \
  -H 'dnt: 1' \
  -H 'flag-real-time-data: true' \
  -H 'origin: https://koala.sh' \
  -H 'priority: u=1, i' \
  -H 'referer: https://koala.sh/chat' \
  -H 'sec-ch-ua: "Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"' \
  -H 'sec-ch-ua-mobile: ?0' \
  -H 'sec-ch-ua-platform: "Windows"' \
  -H 'sec-fetch-dest: empty' \
  -H 'sec-fetch-mode: cors' \
  -H 'sec-fetch-site: same-origin' \
  -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36' \
  -H 'visitor-id: M104xcG4CrFMUerYxF05' \
  --data-raw '{"input":"1","inputHistory":[],"outputHistory":[],"model":"gpt-4.1-mini"}'




curl 'https://koala.sh/api/gpt/' \
  -H 'accept: text/event-stream' \
  -H 'accept-language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7' \
  -H 'content-type: application/json' \
  -b '_ga=GA1.1.135562489.1750346767; crisp-client%2Fsession%2Fb21d4851-f776-4e10-bd26-bef59f54886b=session_089e7dd9-abf3-4030-9a18-471b53b0bd5c; __stripe_mid=38b1254a-4bf6-47b7-bea2-521320c2ec7eccf3f0; _ga_9LCF2TJ2CY=GS2.1.s1750346767$o1$g1$t1750347235$j56$l0$h0; cf_clearance=YYMxb4yyeVm1PbloBVjeBoLgVuWA_ZHKlhCocXqkelg-1750604658-1.2.1.1-6rSwpk64gwSlGGQ8B1Jz7uOhOaRmoJ7badfxHDZ45Oa5WSLMiVO9Og3NSHdR8vO7TxvPv7RnuBYlhQnga9uBBmPKHUr8yPvC9749fe87Ak626xn9BWDf8gWCoYC4bvPCibP.8UUoMjCr36VCeCD458XAnXwY2UdixKzLdEhZ7PjopyvGiEnHuE.eHB61T.FT0czkeNg5Gff1E5Ne7ciD_EpWY58FlflGxv1dvuz__e8VMh96zbqVMvyeOQ64rgW1QFVEbvZJmNCV.dyke76F.6MrdkfpLU.D518YEovmgwrrFZZHxcpGYBjtjiEvBy37_ZrEFxsKuvqN87zIUqK6PksWn3pz3ecCi1Fk8Fvp3RE; _iidt=ZNotD0v/7EryLDKgMfPJkHRUD0wkAF2z640m0j7Bg/Yhml3oFu1ZrI01GTDSk+zMKV0xEi93enabFTn9Oj23+KYdqPqHM3+1pmUDLac=; _vid_t=otB8AS0XrWc4IFyp/yLrAS7/4sA7Gx09/XvnpcS3YjoBf4ilhBCRXZqSmnVCP8wOREn1C3VgFK/x00Lqr0qXo+6C5L7lIX6xUQaJ8PM=; __stripe_sid=c2cc3f5c-38d0-474f-9ff2-2b7ad43aff1d0628cb; ph_phc_sUBgtFpFGfL4lIY24ZS4PcZTNaRvtHCCh3XdWQE29CO_posthog=%7B%22distinct_id%22%3A%2201979833-dae0-774d-afef-6677cf0db295%22%2C%22%24sesid%22%3A%5B1750605485799%2C%2201979833-f2af-709b-b7cb-502b837c22d8%22%2C1750605230767%5D%7D' \
  -H 'dnt: 1' \
  -H 'flag-real-time-data: true' \
  -H 'origin: https://koala.sh' \
  -H 'priority: u=1, i' \
  -H 'referer: https://koala.sh/chat' \
  -H 'sec-ch-ua: "Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"' \
  -H 'sec-ch-ua-mobile: ?0' \
  -H 'sec-ch-ua-platform: "Windows"' \
  -H 'sec-fetch-dest: empty' \
  -H 'sec-fetch-mode: cors' \
  -H 'sec-fetch-site: same-origin' \
  -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36' \
  -H 'visitor-id: M104xcG4CrFMUerYxF05' \
  --data-raw $'{"input":"3","inputHistory":["1","2"],"outputHistory":["Hello\u0021 How can I assist you today?","Hi again\u0021 What would you like help with?"],"model":"gpt-4.1-mini"}'

# current  ask 3
1
Hello! How can I assist you today?
2
Hi again! What would you like help with?
3
Counting along! How can I assist you with "3"?


https://deepinfra.com/chat

curl "https://api.deepinfra.com/v1/openai/chat/completions" \
  -H "Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7" \
  -H "Connection: keep-alive" \
  -H "Content-Type: application/json" \
  -H "DNT: 1" \
  -H "Origin: https://deepinfra.com" \
  -H "Referer: https://deepinfra.com/" \
  -H "Sec-Fetch-Dest: empty" \
  -H "Sec-Fetch-Mode: cors" \
  -H "Sec-Fetch-Site: same-site" \
  -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36" \
  -H "X-Deepinfra-Source: web-page" \
  -H "accept: text/event-stream" \
  -H "sec-ch-ua: "Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"" \
  -H "sec-ch-ua-mobile: ?0" \
  -H "sec-ch-ua-platform: "Windows"" \
  --data-raw "{"model":"deepseek-ai/DeepSeek-R1-Turbo","messages":[{"role":"system","content":"Be a helpful assistant"},{"role":"user","content":"hi"}],"stream":true,"stream_options":{"include_usage":true,"continuous_usage_stats":true}}"




curl "https://api.deepinfra.com/v1/openai/chat/completions"   -H "Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7"   -H "Connection: keep-alive"   -H "Content-Type: application/json"   -H "DNT: 1"   -H "Origin: https://deepinfra.com"   -H "Referer: https://deepinfra.com/"   -H "Sec-Fetch-Dest: empty"   -H "Sec-Fetch-Mode: cors"   -H "Sec-Fetch-Site: same-site"   -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"   -H "X-Deepinfra-Source: web-page"   -H "accept: text/event-stream"   -H "sec-ch-ua: "Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24""   -H "sec-ch-ua-mobile: ?0"   -H "sec-ch-ua-platform: "Windows""   --data-raw "{"model":"deepseek-ai/DeepSeek-Prover-V2-671B","messages":[{"role":"system","content":"Be a helpful assistant"},{"role":"user","content":"hi"}],"stream":true,"stream_options":{"include_usage":true,"continuous_usage_stats":true}}"







curl "https://api.deepinfra.com/v1/openai/chat/completions" \
  -H "Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7" \
  -H "Connection: keep-alive" \
  -H "Content-Type: application/json" \
  -H "DNT: 1" \
  -H "Origin: https://deepinfra.com" \
  -H "Referer: https://deepinfra.com/" \
  -H "Sec-Fetch-Dest: empty" \
  -H "Sec-Fetch-Mode: cors" \
  -H "Sec-Fetch-Site: same-site" \
  -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36" \
  -H "X-Deepinfra-Source: web-page" \
  -H "accept: text/event-stream" \
  -H "sec-ch-ua: "Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"" \
  -H "sec-ch-ua-mobile: ?0" \
  -H "sec-ch-ua-platform: "Windows"" \
  --data-raw "{"model":"deepseek-ai/DeepSeek-Prover-V2-671B","messages":[{"role":"system","content":"Be a helpful assistant"},{"role":"user","content":"hi"}],"stream":true,"stream_options":{"include_usage":true,"continuous_usage_stats":true}}"




 default_model = "deepseek-ai/DeepSeek-V3-0324"
    default_vision_model = "microsoft/Phi-4-multimodal-instruct"
    vision_models = [default_vision_model, "meta-llama/Llama-3.2-90B-Vision-Instruct"]
    models = [
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/Deedefault_modelpSeek-Prover-V2-671B",
        "Qwen/Qwen3-235B-A22B",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-32B",
        "Qwen/Qwen3-14B",
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "microsoft/phi-4-reasoning-plus",
        "microsoft/meta-llama/Llama-Guard-4-12B",
        "Qwen/QwQ-32B",
        default_model,
        "google/gemma-3-27b-it",
        "google/gemma-3-12b-it",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "deepseek-ai/DeepSeek-V3",
        "mistralai/Mistral-Small-24B-Instruct-2501",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-Turbo",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "microsoft/phi-4",
        "microsoft/WizardLM-2-8x22B",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2-72B-Instruct",
        "cognitivecomputations/dolphin-2.6-mixtral-8x7b",
        "cognitivecomputations/dolphin-2.9.1-llama-3-70b",
        "deepinfra/airoboros-70b",
        "lizpreciatior/lzlv_70b_fp16_hf",
        "microsoft/WizardLM-2-7B",
        "mistralai/Mixtral-8x22B-Instruct-v0.1",
    ] + vision_models
    model_aliases = {
        "deepseek-r1-0528": "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-prover-v2-671b": "deepseek-ai/DeepSeek-Prover-V2-671B",
        "deepseek-prover-v2": "deepseek-ai/DeepSeek-Prover-V2-671B",
        "qwen-3-235b": "Qwen/Qwen3-235B-A22B",
        "qwen-3-30b": "Qwen/Qwen3-30B-A3B",
        "qwen-3-32b": "Qwen/Qwen3-32B",
        "qwen-3-14b": "Qwen/Qwen3-14B",
        "llama-4-maverick": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "llama-4-scout": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "phi-4-reasoning-plus": "microsoft/phi-4-reasoning-plus",
        #"": "meta-llama/Llama-Guard-4-12B",
        "qwq-32b": "Qwen/QwQ-32B",
        "deepseek-v3": ["deepseek-ai/DeepSeek-V3", "deepseek-ai/DeepSeek-V3-0324"],
        "deepseek-v3-0324": "deepseek-ai/DeepSeek-V3-0324",
        "gemma-3-27b": "google/gemma-3-27b-it",
        "gemma-3-12b": "google/gemma-3-12b-it",
        "phi-4-multimodal": "microsoft/Phi-4-multimodal-instruct",
        "llama-3.1-8b": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "llama-3.2-90b": "meta-llama/Llama-3.2-90B-Vision-Instruct",
        "llama-3.3-70b": "meta-llama/Llama-3.3-70B-Instruct",
        "mixtral-small-24b": "mistralai/Mistral-Small-24B-Instruct-2501",
        "deepseek-r1-turbo": "deepseek-ai/DeepSeek-R1-Turbo",
        "deepseek-r1": ["deepseek-ai/DeepSeek-R1", "deepseek-ai/DeepSeek-R1-0528"],
        "deepseek-r1-distill-llama-70b": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-r1-distill-qwen-32b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "phi-4": "microsoft/phi-4",
        "wizardlm-2-8x22b": "microsoft/WizardLM-2-8x22B",
        "qwen-2-72b": "Qwen/Qwen2-72B-Instruct",
        "dolphin-2.6": "cognitivecomputations/dolphin-2.6-mixtral-8x7b",
        "dolphin-2.9": "cognitivecomputations/dolphin-2.9.1-llama-3-70b",
        "airoboros-70b": "deepinfra/airoboros-70b",
        "lzlv-70b": "lizpreciatior/lzlv_70b_fp16_hf",
        "wizardlm-2-7b": "microsoft/WizardLM-2-7B",
        "mixtral-8x22b": "mistralai/Mixtral-8x22B-Instruct-v0.1"
    }


================================= 可能需要梯子



curl -X POST "https://next.eqing.tech/api/openai/v1/chat/completions" \
     -H "authority: next.eqing.tech" \
     -H "accept: text/event-stream" \
     -H "accept-language: en,fr-FR;q=0.9,fr;q=0.8,es-ES;q=0.7,es;q=0.6,en-US;q=0.5,am;q=0.4,de;q=0.3" \
     -H "cache-control: no-cache" \
     -H "content-type: application/json" \
     -H "origin: https://next.eqing.tech" \
     -H "plugins: 0" \
     -H "pragma: no-cache" \
     -H "referer: https://next.eqing.tech/" \
     -H "sec-ch-ua: \"Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"115\", \"Chromium\";v=\"115\"" \
     -H "sec-ch-ua-mobile: ?0" \
     -H "sec-ch-ua-platform: \"macOS\"" \
     -H "sec-fetch-dest: empty" \
     -H "sec-fetch-mode: cors" \
     -H "sec-fetch-site: same-origin" \
     -H "user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36" \
     -H "usesearch: false" \
     -H "x-requested-with: XMLHttpRequest" \
     --data-raw "{
       "messages": [
         {
           "role": "user",
           "content": "Hello World"
         }
       ],
       "model": "gpt-3.5-turbo",
       "stream": true,
       "temperature": 0.5,
       "presence_penalty": 0,
       "frequency_penalty": 0,
       "top_p": 1
     }" 



curl -N -X POST "https://www.teach-anything.com/api/generate" \
  -H "accept: */*" \
  -H "accept-language: en-US,en;q=0.9" \
  -H "cache-control: no-cache" \
  -H "content-type: application/json" \
  -H "dnt: 1" \
  -H "origin: https://www.teach-anything.com" \
  -H "pragma: no-cache" \
  -H "priority: u=1, i" \
  -H "referer: https://www.teach-anything.com/" \
  -H "sec-ch-us: \"Not?A_Brand\";v=\"99\", \"Chromium\";v=\"130\"" \
  -H "sec-ch-us-mobile: ?0" \
  -H "sec-ch-us-platform: \"Linux\"" \
  -H "sec-fetch-dest: empty" \
  -H "sec-fetch-mode: cors" \
  -H "sec-fetch-site: same-origin" \
  -H "user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36" \
  --data-raw "{"prompt":"你是什么模型"}" \
  --max-time 60



